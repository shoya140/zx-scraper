{
 "metadata": {
  "name": "",
  "signature": "sha256:7982c4e68163ca52008fd84cce3badae05d0c3c2cb9fe778c976ec28f475a1c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#coding: utf-8\n",
      "\n",
      "import time\n",
      "import json\n",
      "import urllib\n",
      "import commands\n",
      "from bs4 import BeautifulSoup\n",
      "from multiprocessing import Pool\n",
      "\n",
      "base_url = 'http://zexy.net'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u8a18\u4e8b\u3092\u53d6\u5f97\u3059\u308b"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean(string):\n",
      "    return string.strip().replace('\\n', '').replace('\\t', '').encode('utf-8')\n",
      "\n",
      "def scrape(url):\n",
      "    html = urllib.urlopen(url)\n",
      "    soup = BeautifulSoup(html)\n",
      "    contents = soup.find('div', attrs={'id':'contents'})\n",
      "    if not contents:\n",
      "        return\n",
      "    \n",
      "    # main\n",
      "    main = soup.find('article',attrs={'id':'h1_box'})\n",
      "    title = main.find('h1')\n",
      "    description = main.find('p')\n",
      "    data = {\n",
      "        'url': url,\n",
      "        'title': clean(title.text),\n",
      "        'description': clean(description.text)\n",
      "    }\n",
      "    image_section = main.find('section', attrs={'class':'main_img'})\n",
      "    if image_section:\n",
      "        image = image_section.find('img')\n",
      "        data.update({'image': clean(base_url + image['src'])})\n",
      "\n",
      "    # tags\n",
      "    tag = soup.find('ul', attrs={'class':'tag_icon'})\n",
      "    if tag:\n",
      "        tags = tag.findAll('li')\n",
      "        data.update({'tags':[clean(x.text) for x in tags]})\n",
      "    else:\n",
      "        # \u30bf\u30b0\u306e\u4ed8\u3044\u3066\u3044\u306a\u3044\u8a18\u4e8b\u3082\u3042\u308b http://zexy.net/article/app000000791/\n",
      "        data.update({'tags':[]})\n",
      "    \n",
      "    # articles\n",
      "    articles = soup.findAll('article', attrs={'class':['', 'no_s']})\n",
      "    da = []\n",
      "    for article in articles:\n",
      "        d = {}\n",
      "        title = article.find('h2')\n",
      "        if title:\n",
      "            d.update({'title': clean(title.text)})\n",
      "        images = article.findAll('img')\n",
      "        if images: \n",
      "            d.update({'images':[clean(base_url + x['src']) for x in images]})\n",
      "        photo_read = article.find('p', attrs={'class':'photo_read'})\n",
      "        if photo_read:\n",
      "            d.update({'photo_read': clean(photo_read.text)})\n",
      "        price = article.find('section', attrs={'class':'price'})\n",
      "        if price:\n",
      "            d.update({'price': clean(price.text)})\n",
      "        text = article.find('p', attrs={'class':'item1_text'})\n",
      "        if text: \n",
      "            d.update({'text': clean(text.text)})\n",
      "        column = article.find('section', attrs={'class':'column'})\n",
      "        if column: \n",
      "            d.update({'column': clean(column.text)})\n",
      "        da.append(d)\n",
      "    data.update({'articles':da})\n",
      "\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists('./data/'):\n",
      "    os.makedirs('./data/')\n",
      "\n",
      "for j in range(0, 16):\n",
      "    urls = ['http://zexy.net/article/app%09d' %i for i in range(j*100, j*100+100)]\n",
      "    pl = Pool()\n",
      "    %time sc = pl.map(scrape, urls)\n",
      "    data = [s for s in sc if s]\n",
      "    pl.terminate()\n",
      "    print \"----exported %d articles\" % len(data)\n",
      "    \n",
      "    # \u9014\u4e2d\u3067\u6b62\u307e\u308b\u53ef\u80fd\u6027\u3092\u8003\u3048\u3066\u30d5\u30a1\u30a4\u30eb\u3092100\u8a18\u4e8b\u3054\u3068\u306b\u5206\u5272\n",
      "    fname = './data/out%i.json' %j\n",
      "    f = open(fname,'w')\n",
      "    f.write(json.dumps(data, ensure_ascii=False, indent=2))\n",
      "    f.close()\n",
      "    time.sleep(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u5206\u5272\u3057\u305f\u8a18\u4e8b\u3092\u7d71\u5408\n",
      "data = []\n",
      "for i in range(16):\n",
      "    fname = './data/out%d.json' %i\n",
      "    f = open(fname)\n",
      "    data.extend(json.load(f))\n",
      "    f.close()\n",
      "print len(data)\n",
      "\n",
      "f = open('./data/out.json','w')\n",
      "f.write(json.dumps(data, ensure_ascii=False, indent=2).encode('utf-8'))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "947\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u753b\u50cf\u3092\u53d6\u5f97\u3059\u308b"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getImagesOfArticle(d):\n",
      "    if 'image' in d.keys():\n",
      "        commands.getoutput('wget ' + d['image'] + ' -P ./images/')\n",
      "        for a in d['articles']:\n",
      "            if 'images' in a.keys():\n",
      "                for img in a['images']:\n",
      "                    commands.getoutput('wget ' + img + ' -P ./images/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('./data/out.json')\n",
      "data = json.load(f)\n",
      "f.close()\n",
      "\n",
      "for i in range(len(data)/100+1):\n",
      "    if i == 9:\n",
      "        data_set = data[i*100:]\n",
      "    else:\n",
      "        data_set = data[i*100:i*100+99]\n",
      "    pl = Pool()\n",
      "    %time sc = pl.map(getImagesOfArticle, data_set)\n",
      "    pl.terminate()\n",
      "    print \"exported %d \" % i\n",
      "    time.sleep(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u7279\u5b9a\u306e\u30bf\u30b0\u304c\u3064\u3044\u3066\u3044\u308b\u753b\u50cf\u306e\u307f\u53d6\u5f97\u3059\u308b"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getImagesOfTag(tag):\n",
      "    for d in data:\n",
      "        if tag in d['tags']:\n",
      "            print d['title']\n",
      "            if 'image' in d.keys():\n",
      "                commands.getoutput('wget ' + d['image'] + ' -P ./images/keyword')\n",
      "            for a in d['articles']:\n",
      "                if 'images' in a.keys():\n",
      "                    for img in a['images']:\n",
      "                        commands.getoutput('wget ' + img + ' -P ./images/keyword')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('./data/out.json')\n",
      "data = json.load(f)\n",
      "f.close()\n",
      "getImagesOfTag(u'\u5927\u4eba\u304b\u308f\u3044\u3044')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u5927\u4eba\u304b\u308f\u3044\u3044\uff01\u3000\u30c9\u30ec\u30b9\u9078\u3073\u306e\uff12\u5927\u30dd\u30a4\u30f3\u30c8\n",
        "\u304d\u3085\u3063\u3068\u5c0f\u9854\u306b\uff01\u3000\u82b1\u5ac1\u201c\u7f8e\u76db\u308a\u201d\u30d8\u30a2selection"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u304a\u82b1\u306b\u3046\u3063\u3068\u308a\uff01\u3000\u30d5\u30e9\u30ef\u30fc\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30b1\u30fc\u30ad7\u9078"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u30ca\u30c1\u30e5\u30e9\u30eb\u3067\u304b\u308f\u3044\u3044 \u30a6\u30a3\u30c3\u30b0\u3092\u4f7f\u3063\u305f\u82b1\u5ac1\u30d8\u30a2\u30ab\u30bf\u30ed\u30b010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u5074\u9762\u306e\u30c7\u30b6\u30a4\u30f3\u306b\u6ce8\u76ee\u3057\u305f\u3044\u30a8\u30f3\u30b2\u30fc\u30b8\u30ea\u30f3\u30b0\uff33election"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\u9023\u8f09]\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30c7\u30b6\u30a4\u30ca\u30fc\u7acb\u539f\u7dbe\u4e43vol.13\u300e\u30d6\u30e9\u30a4\u30ba\u30e1\u30a4\u30c9\u300f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\u9023\u8f09]\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30c7\u30b6\u30a4\u30ca\u30fc\u7acb\u539f\u7dbe\u4e43vol.17\u300e\u30d1\u30fc\u30c6\u30a3\u300f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\u9023\u8f09]\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30c7\u30b6\u30a4\u30ca\u30fc\u7acb\u539f\u7dbe\u4e43vol.18\u300e\u30cf\u30ef\u30a4\u6319\u5f0f\u300f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\u9023\u8f09]\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30c7\u30b6\u30a4\u30ca\u30fc\u7acb\u539f\u7dbe\u4e43vol.21\u300e\u30d6\u30e9\u30a4\u30ba\u30eb\u30fc\u30e0\u300f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\u9023\u8f09]\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30c7\u30b6\u30a4\u30ca\u30fc\u7acb\u539f\u7dbe\u4e43vol.24\u300eLOVE\u30e9\u30a4\u30c8\u300f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u304b\u3093\u305f\u3093\u266a\u3000\u304b\u308f\u3044\u3044\u266a\u3000\u624b\u4f5c\u308a\u30d8\u30c3\u30c9\u30c9\u30ec\u30b9\u3000\u30ab\u30bf\u30ed\u30b0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u304b\u3093\u305f\u3093\u266a\u3000\u304b\u308f\u3044\u3044\u266a\u3000\u624b\u4f5c\u308a\u30a2\u30af\u30bb\u30b5\u30ea\u30fc\u3000\u30ab\u30bf\u30ed\u30b0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\u9023\u8f09]\u30a6\u30a8\u30c7\u30a3\u30f3\u30b0\u30c7\u30b6\u30a4\u30ca\u30fc\u7acb\u539f\u7dbe\u4e43vol.26\u300eDIY\u300f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}